import java.io.IOException;
import java.util.logging.Level;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Writable;
//import org.apache.hadoop.io.SequenceFile;
//import org.apache.hadoop.io.Writable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;

//import org.apache.hadoop.mapreduce.Mapper.Context;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;

public class BetaMapper<KEYIN, VALUEIN, KEYOUT, VALUEOUT> extends Mapper<KEYIN, VALUEIN, KEYOUT, VALUEOUT> {

	Configuration conf = new Configuration();
	Job nestedJob;
	
	Path nestedJobInputPath;
	Path nestedJobOutputPath;
	
	Path innerWorks = new Path("/tmp/");
	
	String writerType = null;
	String readerType = "SequenceFile";
	String condition = null;
	
	String nestedLevel = null;
	
	WriterFactory writerFactory = new WriterFactory();
	CommonWriterUtils writer;
	
	ReaderFactory readerFactory = new ReaderFactory();
	CommonReaderUtils reader;
	
	// TODO Add commented structure
	@Override
	public void run(Context context) throws IOException, InterruptedException{
		
		setup(context);
			try {
				setupWorkflow(context);
			} catch (ClassNotFoundException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			} catch (InstantiationException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			} catch (IllegalAccessException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
		cleanup(context);
	}

	// TODO Add commented structure
	private void setupWorkflow(Context context) throws IOException, InterruptedException, ClassNotFoundException, InstantiationException, IllegalAccessException {
		
		System.out.println(innerWorks);
		
		//conf.set("hadoop.job.ugi", context.getConfiguration().getResource("hadoop.job.ugi").toString());
		
		
		//System.out.println("Fuck knows what i'm looking for: " + );
		
		nestedJob = new Job(conf);
		
		setupNestedJob(nestedJob, conf, condition);
		
		// TODO implement an uniform naming scheme
		//nestedJob.setJobName("Layer-2");
		
			setupInternalWR(context);
		
		nestedLevel = nestedJob.getJobName();	
			
		//condition = "something";

		// Implement Condition thing;	
		setupNestedMap(context);
			
		//
		
		setupNestedJob(nestedJob,conf, condition);
		
		condition = "something";
		
		setupNesting(nestedJob, conf, condition);
		
		while(executeNestedJob(context) != true){
			// busy wait until nesting is completed
		}
		
		setupNormalMap(context);
		
	}
	
	
	// TODO Add commented structure
	protected void setupNestedJob(Job job, Configuration conf, String condition) throws IOException{
		setupNesting(nestedJob, conf, condition);
	}
	
	// TODO Add commented structure
	protected void setupNesting(Job job, Configuration conf, String condition ) throws IOException{
		// User provided details for nested job configuration
	}
	
	
	//TODO document method behavior
	
	private void setupInternalWR(Context context)
		throws IOException, ClassNotFoundException, InstantiationException,
							IllegalAccessException, InterruptedException{
		
		//nestedJobInputPath = writer.getPath();
		nestedJobInputPath = new Path(innerWorks + "/inceptions/" + nestedJob.getJobName() + "/" + context.getTaskAttemptID().toString());
		//nestedJobInputPath = new Path("/tmp/outputs/1");
		//nestedJobOutputPath = new Path("/tmp/outputs/2");
		//nestedJobOutputPath = new Path(innerWorks + "/outputs/" + nestedJob.getJobName() + "/" + context.getTaskAttemptID());
		
		
		//SequenceFileInputFormat.addInputPath(nestedJob, nestedJobInputPath);
		//SequenceFileOutputFormat.setOutputPath(nestedJob, nestedJobOutputPath);
		
		
		if(SequenceFileInputFormat.class.getName() == nestedJob.getInputFormatClass().getName()){
    		SequenceFileInputFormat.addInputPath(nestedJob, nestedJobInputPath);
    		writerType = "SequenceFile";
		}
    				
		if(TextInputFormat.class.getName() == nestedJob.getInputFormatClass().getName()){
			FileInputFormat.addInputPath(nestedJob, nestedJobInputPath);
			writerType = "BufferFile";
		}
		
		
		//FIXME either fix or remove bufered output all together 
		
	}
	
	protected void setupNestedMap(Context context) throws IOException, InterruptedException, ClassNotFoundException, InstantiationException, IllegalAccessException{

		try {
			System.out.println("In the writer and the type is : " + writerType);
			writer = writerFactory.makeWriter(context, innerWorks, nestedLevel, writerType);
			//writer = new NestedWriterSF<KEYIN, VALUEIN>(context, innerWorks, nestedJob.getJobName());
			//writer = writerFactory.makeWriter(context, writerType);
		} catch (Exception e) {
			e.printStackTrace();
		}
		  
		  while(context.nextKeyValue()){
			  nestedMap(context.getCurrentKey(), context.getCurrentValue(), condition);
		  }
		  
	    writer.close();
		 
	    /* if the user supplies a body for the nested job running run this: */
	    
	 //   while(executeNestedJob() != true){
	    	// we busy wait for the nested job to finalize;
	 //   }
	}
	
	protected void nestedMap (KEYIN key, VALUEIN value, String condition) throws IOException, InterruptedException{
		System.out.println(key + " / " + value);
	
		writer.write(key, value);
	}
	
	protected boolean executeNestedJob(Context context) throws ClassNotFoundException{
		
		// TODO - maybe change condition to something else (ex: anything but null)
		if (condition != null){	

			nestedJobOutputPath = new Path(innerWorks + "/outputs/" + nestedJob.getJobName() + "/" + context.getTaskAttemptID());

			if(SequenceFileOutputFormat.class.getName() == nestedJob.getOutputFormatClass().getName()){
				SequenceFileOutputFormat.setOutputPath(nestedJob, nestedJobOutputPath);
				readerType = "SequenceFile";
			}

			//FIXME either fix or remove buffered output all together 

			if(TextOutputFormat.class.getName() == nestedJob.getOutputFormatClass().getName()){
				FileOutputFormat.setOutputPath(nestedJob, nestedJobOutputPath);
				readerType = "BufferFile";
			}


			try{
				nestedJob.waitForCompletion(true);
			} catch (IOException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			} catch (ClassNotFoundException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
		}
		return true;
	}
	
	private void setupNormalMap(Context context) throws IOException, InterruptedException {
		
		try{
			System.out.println("In the reader and the reader is of type: " + readerType);
			//reader = readerFactory.makeReader(context, readerType);
			
			System.out.println("Condition is :  " + condition);
			
			reader = readerFactory.makeReader(context, innerWorks, nestedJob.getJobName(), readerType, condition);
		}catch (Exception ex){
			ex.printStackTrace();
		}
		
		while(reader.next()){
			map(reader.getKey(), reader.getValue(), context);
		}
		
	}
	
	@SuppressWarnings("unchecked")
	protected void map(Writable key, Writable value, Context context) throws IOException, InterruptedException{
		
		System.out.println(key.getClass().getName() +" / "+ value.getClass().getName());
		
		context.write((KEYOUT) key, (VALUEOUT) value);
	}
	
	
	

}
